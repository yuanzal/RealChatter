# -*- coding: utf-8 -*-
"""
免费版模型专属配置文件：千问1.8B 4bit量化
基于全局量化配置（config/model.py）补充免费版个性化参数
仅定义专属配置，通用配置从全局继承，保证配置一致性
"""
# 核心：导入模型全局量化配置（必须执行，否则无法继承通用规则）
from config.model import MODEL_GLOBAL_CONFIG

# 免费版（千问1.8B）完整配置 = 全局通用配置 + 版本专属配置
# 使用**解包语法继承全局配置，再通过键值对覆盖/补充专属参数
free_model_config = {
    # 1. 完全继承全局量化配置（核心，不可删除）
    # 包含：量化框架(GPTQ)、4bit通用参数、自动检测设备、模型/分词器通用加载规则
    **MODEL_GLOBAL_CONFIG,

    # 2. 免费版专属模型路径（核心，需根据本地模型文件位置修改）
    # 请将该路径改为你本地「千问1.8B 4bit量化模型」的实际存储路径
    # 示例格式：本地相对路径/绝对路径，模型文件夹内需包含量化后的权重、配置文件
    "model_path": "./models/qwen-1_8b-chat-4bit-gptq",

    # 3. 免费版专属资源限制（适配16G内存核心需求）
    "max_memory": "8G",  # 免费版最大内存/显存占用，不超过8G，预留内存给其他进程

    # 4. 免费版专属推理参数（贴合千问1.8B 4bit模型能力）
    "max_context_len": 1024,  # 最大上下文长度，适配模型量化后理解能力
    "max_gen_len": 512,       # 最大生成长度，日常聊天场景足够使用
    "timeout": 60.0,           # 推理超时时间，严格符合「接口返回≤3s」需求
}